{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bfd774-eddd-4c54-b76a-378087af568d",
   "metadata": {},
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 2: Tokenization, Morphological Analysis, and Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437ede2-3caf-4c98-8031-a2e81f4fb234",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"link.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e5931-27fa-49b2-a404-90be1d506fe3",
   "metadata": {},
   "source": [
    "* [2.0 Imports and Setup](#2.0)\n",
    "* [2.1 An Introduction to fugashi](#2.1)\n",
    "    - [2.1.1 Setup](#2.1.1)\n",
    "    - [2.1.2 Morphological Analysis Mini Project: Automatic Fuseji](#2.1.2)\n",
    "    - [2.1.3 Censoring Unknown Words](#2.1.3)\n",
    "    - [2.1.4 Use Readings to Censor only Part of Words](#2.1.4)\n",
    "* [2.2 Improving Tokenization Quality with a User Dictionary](#2.2)\n",
    "    - [2.2.1 Why Make a Custom Tokenizer Dictionary?](#2.2.1)\n",
    "    - [2.2.2 Generating a MeCab User Dictionary](#2.2.2)\n",
    "    - [2.2.3 Creating a SudachiPy User Dictionary](#2.2.3)\n",
    "    - [2.2.4 Sourcing Your Own Data](#2.2.4)\n",
    "    - [2.2.5 Sourcing Internet Data](#2.2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41cd62-2e6b-417c-9538-baa88282dd7c",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='2.0'></a><a id='2.0'></a>\n",
    "# 2.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e7a591-5585-47c6-aa31-200bf84b584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chp02 exists.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_root = Path(\"chp02\")\n",
    "req_file = data_root / \"requirements_2.txt\"\n",
    "\n",
    "if not data_root.is_dir():\n",
    "    data_root.mkdir()\n",
    "else:\n",
    "    print(f\"{data_root} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6813c5-94c9-4600-a3f2-86e732f345c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chp02/requirements_2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "fugashi[unidic]==1.2.1\n",
    "watermark==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb52e1d7-d29b-4ede-8875-de63c06d7b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "check1 = ('google.colab' in sys.modules)\n",
    "check2 = (os.environ.get('CLOUDSDK_CONFIG')=='/content/.config')\n",
    "IS_COLAB = True if (check1 or check2) else False\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --quiet -r {req_file}\n",
    "    !python -m unidic download\n",
    "    print(\"Packages installed.\")\n",
    "else:\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ab493c-8720-4ddb-9a4f-0694bbb8485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "sys    : 3.8.12 (default, Dec 13 2021, 20:17:08) \n",
      "[Clang 13.0.0 (clang-1300.0.29.3)]\n",
      "fugashi: 1.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standard Library imports\n",
    "from importlib.metadata import version\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import fugashi\n",
    "from fugashi import Tagger\n",
    "from random import sample\n",
    "from watermark import watermark\n",
    "\n",
    "def HR():\n",
    "    print(\"-\"*50)\n",
    "\n",
    "# Examine all imported packages\n",
    "print(watermark(iversions=True, globals_=globals(),python=True, machine=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f223b7-5ade-4245-9c9e-b2d6102bfd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported specified packages.\n"
     ]
    }
   ],
   "source": [
    "assert version('fugashi') == '1.2.1'\n",
    "\n",
    "print(\"Successfully imported specified packages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab356d-0223-4e1f-8ab4-df061bfd669b",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='2.1'></a><a id='2.1'></a>\n",
    "# 2.1 An Introduction to fugashi\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Adapted from [2.1-fugashi-fuseji.ipynb](https://github.com/octanove/janlpbook-code/blob/main/en/2.1-fugashi-fuseji.ipynb) by Paul O'Leary McCann and Masato Hagiwara \n",
    "\n",
    "\n",
    "fugashi provides four different dictionaries pre‐packaged:\n",
    "\n",
    "1. JumanDic\n",
    "2. UniDic\n",
    "3. unidic‐lite\n",
    "4. IPAdic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663587c6-7c6a-4249-9b39-0ed5e391e5c6",
   "metadata": {},
   "source": [
    "<a name='2.1.1'></a><a id='2.1.1'></a>\n",
    "## 2.1.1 Setup\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Assuming installation above. Test via the command-line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db354171-1a00-47f8-b300-52e383e8b861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毎年 東麻布 で は かかし 祭り が 開催 さ れ ます\n"
     ]
    }
   ],
   "source": [
    "!echo \"毎年東麻布ではかかし祭りが開催されます\" | fugashi -O wakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16754f7b-5ccb-4d3c-acd5-3ec0bd53f444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[形態, 素, 解析, を, やっ, て, み, た]\n",
      "=====\n",
      "形態\t形態\tケイタイ\n",
      "素\t素\tソ\n",
      "解析\t解析\tカイセキ\n",
      "を\tを\tヲ\n",
      "やっ\t遣る\tヤッ\n",
      "て\tて\tテ\n",
      "み\t見る\tミ\n",
      "た\tた\tタ\n"
     ]
    }
   ],
   "source": [
    "tagger = fugashi.Tagger()\n",
    "\n",
    "text = \"形態素解析をやってみた\"\n",
    "words = tagger(text)\n",
    "print(words)\n",
    "print(\"=====\")\n",
    "\n",
    "for word in words:\n",
    "    print(word.surface, word.feature.lemma, word.feature.kana, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabed6a7-b81c-4e2f-bb4a-a0b9be8d1a77",
   "metadata": {},
   "source": [
    "<a name='2.1.2'></a><a id='2.1.2'></a>\n",
    "## 2.1.2 Morphological Analysis Mini Project: Automatic Fuseji\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91c2d1e-ddcf-41c9-902d-9f5754dfd9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "犯人は◯◯\n",
      "◯◯タワーの高さは333m\n"
     ]
    }
   ],
   "source": [
    "tagger = Tagger()\n",
    "\n",
    "def fuseji_node(text, ratio=1.0):\n",
    "    \"\"\"This function will take a node from tokenization and actually replace parts of it with filler characters.\"\"\"\n",
    "    ll = len(text)\n",
    "    idxs = sample(range(ll), max(1, int(ratio * ll)))\n",
    "    out = []\n",
    "    for ii, cc in enumerate(text):\n",
    "        out.append(\"◯\" if ii in idxs else cc)\n",
    "    return \"\".join(out)\n",
    "\n",
    "\n",
    "def fuseji_text(text, ratio=1.0):\n",
    "    \"\"\"Given an input string, apply fuseji. \"\"\"\n",
    "    out = []\n",
    "    for node in tagger(text):\n",
    "        # Normal Japanese text doesn't use white space, but this is necessary \n",
    "        # if you include latin text, for example. \n",
    "        out.append(node.white_space)\n",
    "        if node.feature.pos2 != \"固有名詞\":\n",
    "            out.append(node.surface)\n",
    "        else:\n",
    "            out.append(fuseji_node(node.surface))\n",
    "    return \"\".join(out)\n",
    "\n",
    "print(fuseji_text(\"犯人はヤス\"))\n",
    "print(fuseji_text(\"東京タワーの高さは333m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000d4ced-7670-44c0-998b-9b81a737e965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毎年\t名詞,副詞可能,*,*,*,*,毎年,マイトシ,マイトシ\n",
      "東麻布\t名詞,固有名詞,地域,一般,*,*,東麻布,ヒガシアザブ,ヒガシアザブ\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "かかし\t名詞,一般,*,*,*,*,かかし,カカシ,カカシ\n",
      "祭り\t名詞,一般,*,*,*,*,祭り,マツリ,マツリ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "開催\t名詞,サ変接続,*,*,*,*,開催,カイサイ,カイサイ\n",
      "さ\t動詞,自立,*,*,サ変・スル,未然レル接続,する,サ,サ\n",
      "れ\t動詞,接尾,*,*,一段,連用形,れる,レ,レ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "!echo \"毎年東麻布ではかかし祭りが開催されます\" | fugashi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152674f-9f06-4488-acd2-8272e8eeb70c",
   "metadata": {},
   "source": [
    "<a name='2.1.3'></a><a id='2.1.3'></a>\n",
    "## 2.1.3 Censoring Unknown Words\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec7b03ed-610c-4faa-b5fd-7f28b1dbbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "犯人は◯◯\n",
      "魔法の言葉は◯◯◯◯◯\n",
      "『さかしま』（仏: ◯ ◯◯◯◯◯◯◯）は、◯◯◯◯の作家◯◯◯◯＝◯◯◯・◯◯◯◯◯◯による小説\n",
      "◯◯爆発で最初に解体する爆弾はみかんの形をしている\n"
     ]
    }
   ],
   "source": [
    "def should_hide(node):\n",
    "    \"\"\"Check if this node should be hidden or not. \"\"\"\n",
    "    if node.is_unk:\n",
    "        return True\n",
    "    ff = node.feature\n",
    "    if ff.pos1 == \"名詞\" and ff.pos2 == \"固有名詞\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def fuseji_text(text, ratio=1.0):\n",
    "    \"\"\"Given an input string, apply fuseji. \"\"\"\n",
    "    out = []\n",
    "    for node in tagger(text):\n",
    "        out.append(node.white_space)\n",
    "        word = fuseji_node(node.surface) if should_hide(node) else node.surface\n",
    "        out.append(word)\n",
    "    return \"\".join(out)\n",
    "\n",
    "texts = [\n",
    "    \"犯人はヤス\",\n",
    "    \"魔法の言葉はヒラケゴマ\",\n",
    "    \"『さかしま』（仏: À rebours）は、フランスの作家ジョリス＝カルル・ユイスマンスによる小説\",\n",
    "    \"鈴木爆発で最初に解体する爆弾はみかんの形をしている\",\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(fuseji_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0f019-2c03-45aa-9ea9-b3574e3f5809",
   "metadata": {},
   "source": [
    "<a name='2.1.4'></a><a id='2.1.4'></a>\n",
    "## 2.1.4 Use Readings to Censor only Part of Words\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d40eca7-9b59-41c4-81ba-f91f7e5dccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黒幕の正体はガーランド\n"
     ]
    }
   ],
   "source": [
    "def fuseji_text(text, ratio=1.0):\n",
    "    \"\"\"Given an input string, apply fuseji. \"\"\"\n",
    "    out = []\n",
    "    for node in tagger(text):\n",
    "        out.append(node.white_space)\n",
    "        node_text = node.surface if node.is_unk else node.feature.kana\n",
    "        word = fuseji_node(node_text, ratio=0.5) if should_hide(node) else node.surface\n",
    "        out.append(word)\n",
    "    return \"\".join(out)\n",
    "\n",
    "texts = [\n",
    "    \"黒幕の正体はガーランド\",\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(fuseji_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e1a03-7b1f-4558-ace4-9e455ea74920",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='2.2'></a><a id='2.2'></a>\n",
    "# 2.2 Improving Tokenization Quality with a User Dictionary\n",
    "<a href=\"#top\">[back to top]</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c6264-2702-41e2-b67e-26d8bfbc9899",
   "metadata": {},
   "source": [
    "<a name='2.2.1'></a><a id='2.2.1'></a>\n",
    "## 2.2.1 Why Make a Custom Tokenizer Dictionary?\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "No source code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a3b34-e320-46aa-a24d-18310265bab4",
   "metadata": {},
   "source": [
    "<a name='2.2.2'></a><a id='2.2.2'></a>\n",
    "## 2.2.2 Generating a MeCab User Dictionary\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6114797b-7254-41c1-b55f-a1cb73751a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ドロッチェ,,,100,名 詞,固 有 名 詞,一 般,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n",
      "デデデ,,,100,名 詞,固 有 名 詞,一 般,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n",
      "水しょう,,,100,名 詞,固 有 名 詞,一 般,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "# The Minimal Approach\n",
    "pos = \"名 詞,固 有 名 詞,一 般,*\".split(\",\")\n",
    "words = [\"ドロッチェ\", \"デデデ\", \"水しょう\"]\n",
    "empty = \"*\"\n",
    "\n",
    "for word in words:\n",
    "# pos is four fields, so (26 ‐ 4) == 22\n",
    "    entry = [word, \"\", \"\", \"100\"] + pos + (22 * [empty]) \n",
    "    print(\",\".join(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcba540b-f736-43dc-9530-8ff06f46c30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一般,*,*,*,*,*,*,水 晶,*,ス イ シ ョ ー,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "# The Thorough Approach\n",
    "from fugashi import UnidicFeatures26\n",
    "\n",
    "# field names come from fugashi\n",
    "words = [(\"水 し ょ う\", {\"pron\": \"ス イ シ ョ ー\", \"lemma\": \"水 晶\"})]\n",
    "fields = UnidicFeatures26._fields\n",
    "\n",
    "for word, data in words:\n",
    "    entry = {}\n",
    "    for field in fields:\n",
    "        entry[field] = data.get(field, \"*\")\n",
    "    \n",
    "    # assume pos is hard‐coded\n",
    "    entry[\"pos1\"] = \"名詞\"\n",
    "    entry[\"pos1\"] = \"固有名詞\"\n",
    "    entry[\"pos1\"] = \"一般\"\n",
    "    print(\",\".join(entry.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "571ca9da-7851-4c40-a7df-d56920d15684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黒幕 名詞\n",
      "の 助詞\n",
      "正体 名詞\n",
      "は 助詞\n",
      "ガーランド 名詞\n"
     ]
    }
   ],
   "source": [
    "from fugashi import GenericTagger\n",
    "tagger = GenericTagger()\n",
    "\n",
    "# parse can be used as normal\n",
    "tagger.parse('something')\n",
    "\n",
    "# features from the dictionary can be accessed by field numbers\n",
    "for word in tagger(text):\n",
    "    print(word.surface, word.feature[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "759b0742-182e-43ca-b103-708c4cbb8c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fugashi.fugashi.GenericTagger at 0x103f9cf00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Extra Approach\n",
    "from fugashi import GenericTagger\n",
    "from fugashi import create_feature_wrapper\n",
    "\n",
    "# Add field named \"db_id\" to unidic-lite\n",
    "fields = UnidicFeatures26._fields + (\"db_id\",)\n",
    "\n",
    "# Create GenericTagger instance\n",
    "wrapper = create_feature_wrapper(\"MyFeatures\", fields)\n",
    "\n",
    "# Use GenericTagger with \n",
    "tagger = GenericTagger(\n",
    "    wrapper=wrapper,\n",
    "    # \"-d ...\" # Specify pathway to installed dictionary\n",
    ")\n",
    "\n",
    "tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd17c5-faf0-4591-b0f7-ae3387fe386c",
   "metadata": {},
   "source": [
    "<a name='2.2.3'></a><a id='2.2.3'></a>\n",
    "## 2.2.3 Creating a SudachiPy User Dictionary\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "No source code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f5e90-b56b-4f94-8c86-2ad181fcc741",
   "metadata": {},
   "source": [
    "<a name='2.2.4'></a><a id='2.2.4'></a>\n",
    "## 2.2.4 Sourcing Your Own Data\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "No source code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c7399-ad18-4f4c-b94a-7f79b8196907",
   "metadata": {},
   "source": [
    "<a name='2.2.5'></a><a id='2.2.5'></a>\n",
    "## 2.2.5 Sourcing Internet Data\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "No source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079a931-a235-47ea-8096-d127efd64ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
