{"cells":[{"cell_type":"markdown","metadata":{"id":"bc486a68-32b4-49ee-b83f-c737ee0081e9"},"source":["<a id='top'></a><a name='top'></a>\n","# Chapter 5: Natural Language Generation and Conversion with Transformer\n","\n","## 5.3 Kana-Kanji Conversion with Transformer"],"id":"bc486a68-32b4-49ee-b83f-c737ee0081e9"},{"cell_type":"markdown","metadata":{"id":"427d57d9-8719-4711-b4b9-32e606a8c0bd"},"source":["<table align=\"left\">\n","  <td>\n","    <a href=\"https://colab.research.google.com/github/gbih/nlp/blob/main/ja_nlp_book/chp05_5_3_seq_to_seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","  </td>\n","</table>"],"id":"427d57d9-8719-4711-b4b9-32e606a8c0bd"},{"cell_type":"markdown","metadata":{"id":"cfdf997b-f957-4977-ae2e-91e51a46ad8b"},"source":["* [Imports and Setup](#setup)\n","* [5.3 Kana-Kanji Conversion with Transformer](#5.3)\n","    - [5.3.1 Sequence to Sequence (Seq2Seq) Models](#5.3.1)\n","    - [5.3.2 Converting from Kanji-Kana majiribun into Romaji](#5.3.2)\n","    - [5.3.3 Training and Tokenizing with SentencePiece](#5.3.3)\n","    - [5.3.4 Training a Conversion Model with Fairseq](#5.3.4)\n","    - [5.3.5 Checking created artifacts](#5.3.5)"],"id":"cfdf997b-f957-4977-ae2e-91e51a46ad8b"},{"cell_type":"markdown","metadata":{"id":"4f22c158-28dd-47cf-a0f8-01c530591cf3"},"source":["---\n","<a name='setup'></a><a id='setup'></a>\n","# Imports and Setup\n","<a href=\"#top\">[back to top]</a>"],"id":"4f22c158-28dd-47cf-a0f8-01c530591cf3"},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1670885784275,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"pnRcn305Ngsj"},"outputs":[],"source":["# Option to use downloaded/pre-trained data (assumes Colab platform)\n","USE_GD_DATA = False\n","\n","if USE_GD_DATA:\n","    try:\n","        from google.colab import drive\n","        drive.mount('/content/drive', force_remount=True)\n","        print(\"Creating a local copy of chp05_03...\")\n","        # Assumes prepared data is stored as 'My Drive/chp05_03' on Google Drive \n","        !cp -r /content/drive/MyDrive/chp05_03 /content/chp05_03\n","        print()\n","        !ls -l /content/chp05_03\n","    except Exception as e:\n","        print(f\"Error: {e}\")"],"id":"pnRcn305Ngsj"},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670885786940,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"8d218a66-cb88-48b7-b446-f78f2e9ac892"},"outputs":[],"source":["import pathlib\n","from pathlib import Path\n","\n","data_root = Path(\"chp05_03\")\n","req_file = data_root / \"requirements_5_5_3.txt\"\n","\n","if not data_root.is_dir():\n","    data_root.mkdir()\n","else:\n","    print(f\"{data_root} exists.\")"],"id":"8d218a66-cb88-48b7-b446-f78f2e9ac892"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1670885789702,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"Cd6jWZ1vmBrd","outputId":"4b526d8d-a8ac-4f6b-bb43-b483edef0dfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing chp05_03/requirements_5_5_3.txt\n"]}],"source":["%%writefile {req_file}\n","cutlet==0.1.19\n","fugashi[unidic]==1.2.1\n","sentencepiece==0.1.97\n","fairseq==0.12.2\n","tensorboardX==2.5.1\n","watermark==2.3.1"],"id":"Cd6jWZ1vmBrd"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64938,"status":"ok","timestamp":1670885856884,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"EO3VuT9c857f","outputId":"b934a74f-dfb0-4756-9251-48bab456ec11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing packages\n","\u001b[K     |████████████████████████████████| 364 kB 37.3 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 615 kB 71.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 66.3 MB/s \n","\u001b[K     |████████████████████████████████| 11.0 MB 84.5 MB/s \n","\u001b[K     |████████████████████████████████| 125 kB 74.9 MB/s \n","\u001b[K     |████████████████████████████████| 128 kB 73.6 MB/s \n","\u001b[K     |████████████████████████████████| 118 kB 79.9 MB/s \n","\u001b[K     |████████████████████████████████| 241 kB 83.9 MB/s \n","\u001b[K     |████████████████████████████████| 123 kB 83.2 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 52.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 71.5 MB/s \n","\u001b[?25h  Building wheel for cutlet (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","download url: https://cotonoha-dic.s3-ap-northeast-1.amazonaws.com/unidic-3.1.0.zip\n","Dictionary version: 3.1.0+2021-08-31\n","Downloading UniDic v3.1.0+2021-08-31...\n","unidic-3.1.0.zip: 100% 526M/526M [00:30<00:00, 17.4MB/s]\n","Finished download.\n","Downloaded UniDic v3.1.0+2021-08-31 to /usr/local/lib/python3.8/dist-packages/unidic/dicdir\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libfile-next-perl.\n","(Reading database ... 124020 files and directories currently installed.)\n","Preparing to unpack .../libfile-next-perl_1.16-2_all.deb ...\n","Unpacking libfile-next-perl (1.16-2) ...\n","Selecting previously unselected package ack.\n","Preparing to unpack .../archives/ack_2.22-1_all.deb ...\n","Unpacking ack (2.22-1) ...\n","Setting up libfile-next-perl (1.16-2) ...\n","Setting up ack (2.22-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","\n","** Need to restart runtime after installing sentencepiece **\n","> Runtime > Restart runtime ...\n"]}],"source":["import os\n","import sys\n","check1 = ('google.colab' in sys.modules)\n","check2 = (os.environ.get('CLOUDSDK_CONFIG')=='/content/.config')\n","IS_COLAB = True if (check1 or check2) else False\n","\n","# Need fugashi for cutlet, and need unidic for fugashi\n","if IS_COLAB:\n","    print(\"Installing packages\")\n","    !pip install --quiet -r {req_file}\n","    !apt-get install tree &> /dev/null\n","    !python -m unidic download\n","    !sudo apt-get install ack -qq\n","    print()\n","    print(\"** Need to restart runtime after installing sentencepiece **\")\n","    print(\"> Runtime > Restart runtime ...\")\n","else:\n","    print(\"Running locally.\")"],"id":"EO3VuT9c857f"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4677,"status":"ok","timestamp":1670885886902,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"tTaKzm4amWGp","outputId":"97189ac2-8546-4663-ea91-b2d94867b203"},"outputs":[{"output_type":"stream","name":"stdout","text":["IS_COLAB: True\n","device:cuda\n","--------------------------------------------------\n","Python implementation: CPython\n","Python version       : 3.8.16\n","IPython version      : 7.9.0\n","\n","cutlet       : 0.1.19\n","fairseq      : 0.12.2\n","fugashi      : 1.2.1\n","sentencepiece: 0.1.97\n","tensorboardX : 2.5.1\n","torch        : 1.13.0+cu116\n","watermark    : 2.3.1\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.10.133+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n"]}],"source":["# Standard Library imports\n","from itertools import chain\n","import os\n","import pathlib\n","from pathlib import Path\n","import shlex\n","import shutil\n","import subprocess\n","import sys\n"," \n","# Third-party imports\n","import cutlet\n","import fairseq\n","import sentencepiece as spm\n","import logging\n","import torch\n","from tqdm import tqdm\n","from watermark import watermark\n","\n","# Suppress TensorFlog log messages\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","\n","check1 = ('google.colab' in sys.modules)\n","check2 = (os.environ.get('CLOUDSDK_CONFIG')=='/content/.config')\n","IS_COLAB = True if (check1 or check2) else False\n","print(f\"IS_COLAB: {IS_COLAB}\")\n","\n","katsu = cutlet.Cutlet()\n","\n","_ = torch.manual_seed(42)\n","\n","def HR():\n","    print(\"-\"*50)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"device:{device}\")\n","HR()\n","\n","packages_check=\"cutlet,fairseq,fugashi,sentencepiece,tensorboardX,torch,watermark\"\n","print(watermark(packages=packages_check, python=True,machine=True))"],"id":"tTaKzm4amWGp"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1670885886904,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"c5a526fe-b636-4f69-b294-742f65537ffb","outputId":"85fc4159-fc77-4ee5-baaa-b158fe2c5275"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","data_root:\tchp05_03\n","data_file:\tsentences20210924.tar.bz2\n","data_url:\tjanlpbook.s3.amazonaws.com/sentences20210924.tar.bz2\n","data_dir:\tchp05_03/data\n","data_src:\tchp05_03/data/sentences20210924.tar.bz2\n","data_path:\tchp05_03/data/sentences.csv\n","\n","data_file2:\tcc100.ja.mod1k.txt\n","data_url2:\tjanlpbook.s3.amazonaws.com/cc100.ja.mod1k.txt\n","data_path2:\tchp05_03/data/cc100.ja.mod1k.txt\n","\n"]}],"source":["data_file = \"sentences20210924.tar.bz2\"\n","data_url = f\"janlpbook.s3.amazonaws.com/{data_file}\"\n","data_root = Path(\"chp05_03\") # redefine after runtime restart\n","data_dir = data_root /\"data\"\n","data_src = data_dir / data_file\n","data_path = data_dir / \"sentences.csv\"\n","\n","data_file2 = \"cc100.ja.mod1k.txt\"\n","data_url2 = f\"janlpbook.s3.amazonaws.com/{data_file2}\"\n","data_path2 = data_dir / data_file2\n","\n","print(f\"\"\"\n","data_root:\\t{data_root}\n","data_file:\\t{data_file}\n","data_url:\\t{data_url}\n","data_dir:\\t{data_dir}\n","data_src:\\t{data_src}\n","data_path:\\t{data_path}\n","\n","data_file2:\\t{data_file2}\n","data_url2:\\t{data_url2}\n","data_path2:\\t{data_path2}\n","\"\"\")"],"id":"c5a526fe-b636-4f69-b294-742f65537ffb"},{"cell_type":"markdown","metadata":{"id":"a3e87a8f-a8b1-4782-b2aa-e07d52555d3c"},"source":["---\n","<a name='5.3'></a><a id='5.3'></a>\n","# 5.3 Kana-Kanji Conversion with Transformer\n","<a href=\"#top\">[back to top]</a>"],"id":"a3e87a8f-a8b1-4782-b2aa-e07d52555d3c"},{"cell_type":"markdown","metadata":{"id":"3c546610-4647-48cb-98d1-1704f73ec8cd"},"source":["<a name='5.3.1'></a><a id='5.3.1'></a>\n","## 5.3.1 Sequence to Sequence (Seq2Seq) Models\n","<a href=\"#top\">[back to top]</a>"],"id":"3c546610-4647-48cb-98d1-1704f73ec8cd"},{"cell_type":"markdown","metadata":{"id":"GjCOtrByjQ3G"},"source":["* For the Kana-Kanji conversion, use a Transformer-based Seq2Seq model.\n","* A Seq2Seq model converts a sequence into another sequence.\n","* It consists of two subcomponents, each of which is usually a full neural network with multiple layers:\n","    - An encoder\n","    - A decoder\n","* The encoder converts input into an internal representation, similar to word embeddings. \n","* The decoder takes the representations produced by the encoder and produces the output text.\n","* Here we use a Seq2Seq model with Transformer-based architecture.\n","* Fairseq implements Transformer Seq2Seq, and we will use one of its default Transformer configurations.\n"],"id":"GjCOtrByjQ3G"},{"cell_type":"markdown","metadata":{"id":"643a8660-2df5-479e-9321-1b7b0b991ac5"},"source":["<a name='5.3.2'></a><a id='5.3.2'></a>\n","## 5.3.2 Converting from Kanji-Kana majiribun into Romaji\n","<a href=\"#top\">[back to top]</a>\n","\n","* Create the parallel corpus for Kana-Kanji conversion\n","* Use cutlet to convert Kanji-Kana majiribun to Romaji"],"id":"643a8660-2df5-479e-9321-1b7b0b991ac5"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1670885886905,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"3d681294-818b-4779-a6a3-ff9d4c5dad97","outputId":"fa2b4f6e-1f02-49a5-b5e7-745a22a13779"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Katsu karee wa oishii'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["# Hello-world example\n","katsu = cutlet.Cutlet()\n","katsu.use_foreign_spelling = False\n","katsu.romaji(\"カツカレーは美味しい\")"],"id":"3d681294-818b-4779-a6a3-ff9d4c5dad97"},{"cell_type":"markdown","metadata":{"id":"8007e7a5-4277-4ef0-adcd-d87432574e24"},"source":["* Create a large corpus of raw Japanese texts in order to build a parallel (Romaji to Japanese) corpus.\n","* Use a combination of Tatoeba and CC-100 datasets.\n","* Use a 1/1000 sample of CC-100"],"id":"8007e7a5-4277-4ef0-adcd-d87432574e24"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1670885886907,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"4beb1619-71e9-4871-84bb-12ffe21342ca","outputId":"0fb0cdba-24f6-4d6b-cd0a-1a1b3c66b89f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating: chp05_03/data\n"]}],"source":["if not (data_dir).is_dir():\n","    print(f\"Creating: {data_dir}\")\n","    data_dir.mkdir(parents=True, exist_ok=False)\n","else:\n","    print(f\"{data_dir} exists.\")"],"id":"4beb1619-71e9-4871-84bb-12ffe21342ca"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25592,"status":"ok","timestamp":1670885912480,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"a6d0fd02-5e52-4c8d-ae16-5ca40bab3072","outputId":"513a411d-05e3-4dbe-ed74-275a54f9e291"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading janlpbook.s3.amazonaws.com/sentences20210924.tar.bz2 to chp05_03/data/sentences20210924.tar.bz2\n","Done.\n","--------------------------------------------------\n","Extracting file chp05_03/data/sentences20210924.tar.bz2\n","Done.\n"]}],"source":["# Download and prep the Tatoeba datasets\n","if not data_src.is_file():\n","    print(f\"Downloading {data_url} to {data_src}\")\n","    subprocess.run(shlex.split(f\"wget -q -O {data_src} {data_url}\"))\n","    print(\"Done.\")\n","else:\n","    print(f\"{data_src} exists.\")\n","\n","HR()\n","\n","if not data_path.is_file():\n","    print(f\"Extracting file {data_src}\")\n","    shutil.unpack_archive(data_src, data_dir)\n","    print(\"Done.\")\n","else:\n","    print(f\"{data_path} exists\")"],"id":"a6d0fd02-5e52-4c8d-ae16-5ca40bab3072"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1819,"status":"ok","timestamp":1670885914290,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"65704b44-8a30-4496-b563-f48dd28d231e","outputId":"87dc9645-cc76-4786-e883-e699a215ac8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading janlpbook.s3.amazonaws.com/cc100.ja.mod1k.txt to chp05_03/data/cc100.ja.mod1k.txt\n","Done.\n"]}],"source":["# Download the CC-100 datasets\n","if not data_path2.is_file():\n","    print(f\"Downloading {data_url2} to {data_path2:}\")\n","    subprocess.run(shlex.split(f\"wget -q -O {data_path2:} {data_url2}\"))\n","    print(\"Done.\")\n","else:\n","    print(f\"{data_path2} exists.\")"],"id":"65704b44-8a30-4496-b563-f48dd28d231e"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1670885914292,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"39ffe8d8-3ab5-43d9-aaad-92eac870fbfe","outputId":"772485cc-d75d-465b-c3f3-8d6e55199f52"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\tcmn\t我們試試看！\n","2\tcmn\t我该去睡觉了。\n","3\tcmn\t你在干什麼啊？\n","4\tcmn\t這是什麼啊？\n","5\tcmn\t今天是６月１８号，也是Muiriel的生日！\n"]}],"source":["# Check\n","!head -n 5 {data_path}"],"id":"39ffe8d8-3ab5-43d9-aaad-92eac870fbfe"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1670885914294,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"734a6baa-73cb-424c-9151-3edf5f4bd373","outputId":"80e4ca2b-e993-4bed-a4a6-fdeb6b226642"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('chp05_03/data/sentences.jpn')"]},"metadata":{},"execution_count":8}],"source":["data_file3 = \"sentences.jpn\"\n","data_path3 = data_dir / data_file3\n","data_path3"],"id":"734a6baa-73cb-424c-9151-3edf5f4bd373"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1670885914294,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"hhOiI9GBaRre","outputId":"ecfb2251-0294-45eb-8ccf-c8bf93045c2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test ack compatibility with --perl-regexp on both OSX and Linux:\n","きみにちょっとしたものをもってきたよ。\n"]}],"source":["# OSX: grep changed from grep (GNU grep) 2.5.1 in 10.7 to grep 2.5.1-FreeBSD in OSX 10.8\n","# Accordingly, the FreeBSD grep version no longer supports -P, --perl-regexp\n","# Instead, we use 'ack' to ensure cross-compatibility across OSX and Linux.\n","\n","print(\"Test ack compatibility with --perl-regexp on both OSX and Linux:\")\n","ack_test = !ack -1 '\\tjpn\\t' chp05_03/data/sentences.csv | cut -f 3\n","print(ack_test[0])\n","assert ack_test[0] == \"きみにちょっとしたものをもってきたよ。\", \"Problem with ack\""],"id":"hhOiI9GBaRre"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3315,"status":"ok","timestamp":1670885917599,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"2fc8472d-8afd-4dc3-9231-c441280a77e6","outputId":"b35c0e8f-9b1e-495f-c667-d8e73ae0738c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating chp05_03/data/sentences.jpn\n","--------------------------------------------------\n","きみにちょっとしたものをもってきたよ。\n","何かしてみましょう。\n","私は眠らなければなりません。\n","何してるの？\n","今日は６月１８日で、ムーリエルの誕生日です！\n","--------------------------------------------------\n","12M\tchp05_03/data/sentences.jpn\n"]}],"source":["# Remove extra fields from sentences.csv\n","# Without `cut field 3`, the output is \"1297 jpn きみにちょっとしたものをもってきたよ。\"\n","# With `cut field 3`, the output is \"きみにちょっとしたものをもってきたよ。\"\n","if not Path(data_dir/\"sentences.jpn\").is_file():\n","    print(f\"Creating {data_dir}/sentences.jpn\")\n","    !ack '\\tjpn\\t' {data_dir}/sentences.csv | cut -f 3 > {data_dir}/sentences.jpn\n","else:\n","    print(f\"{data_dir}/sentences.jpn exists.\")\n","\n","HR()\n","\n","!head -n 5 {data_dir}/sentences.jpn\n","HR()\n","!du -h {data_dir}/sentences.jpn"],"id":"2fc8472d-8afd-4dc3-9231-c441280a77e6"},{"cell_type":"markdown","metadata":{"id":"4cde496b-5249-449a-9838-915035f23f81"},"source":["* Open these two files and build two files, a Kanji-Kana majiribun file with the original text, and a Romaji file with the converted text from cutlet.\n","\n","* Use `itertools.chain()` from https://docs.python.org/3/library/itertools.html#itertools.chain. Make an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable, until all of the iterables are exhausted. Used for treating consecutive sequences as a single sequence. "],"id":"4cde496b-5249-449a-9838-915035f23f81"},{"cell_type":"markdown","metadata":{"id":"d1d9aa98-37ae-49b6-bed5-f8ef4fdc31cb"},"source":["## Error: \n","\n","* Looks like `cutlet.Cutlet().romaji()` is choking on this text in cc100.ja.mod1k.txt, line 446182:\n","    \n","```\n","ｺﾝﾊﾞﾝﾊｰヾ(･∀･`o)ﾉ))明細書については、今日中に一通り終わらせないと先行きが不安ですが、普通にムリだろうなと諦めています。\n","```"],"id":"d1d9aa98-37ae-49b6-bed5-f8ef4fdc31cb"},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1670885918021,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"106d38af-03fd-4818-95ca-7dbb98567b9b","outputId":"d33b676f-e6b6-4497-da3f-0fd29c24cdb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["ｺﾝﾊﾞﾝﾊｰヾ(･∀･`o)ﾉ))明細書については、今日中に一通り終わらせないと先行きが不安ですが、普通にムリだろうなと諦めています。\n","--------------------------------------------------\n","Error: substring not found\n","--------------------------------------------------\n","ｺﾝﾊﾞﾝﾊｰ(･∀･`o)ﾉ))明細書については、今日中に一通り終わらせないと先行きが不安ですが、普通にムリだろうなと諦めています。\n","--------------------------------------------------\n","Konbanhaa  )) meisaisho ni tsuite wa, kyoujuu ni hitotoori owarasenaito sakiyuki ga fuan desuga, futsuu ni muri darou na to akiramete imasu.\n"]}],"source":["def test_odoriji():\n","    # cc100.ja.mod1k.txt, line 446182\n","    input = \"ｺﾝﾊﾞﾝﾊｰヾ(･∀･`o)ﾉ))明細書については、今日中に一通り終わらせないと先行きが不安ですが、普通にムリだろうなと諦めています。\"\n","    print(input)\n","    HR()\n","    \n","    try:\n","        print(cutlet.Cutlet().romaji(input))\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","    HR()\n","    \n","    # Hack to replace the odoriji ヾ.\n","    # The other odoriji ゝゞヽ do not seem to causes any errors.\n","    input = input.replace(\"ヾ\", \"\")\n","    print(input)\n","    HR()\n","    \n","    try:\n","        print(cutlet.Cutlet().romaji(input))\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","        \n","test_odoriji()"],"id":"106d38af-03fd-4818-95ca-7dbb98567b9b"},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1670885918022,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"636ef388-fce2-4113-9b96-80f10c8e711d"},"outputs":[],"source":["def line_count(filename):\n","    # Purposely use subprocess for non-async\n","    return int(subprocess.check_output(['wc', '-l', filename]).split()[0])"],"id":"636ef388-fce2-4113-9b96-80f10c8e711d"},{"cell_type":"markdown","metadata":{"id":"d8c017cb-8555-4616-9276-ee9d3d7842b6"},"source":["* GB: For consistency, rename filenames to use underbars as `tatoeba_cc100.kan`"],"id":"d8c017cb-8555-4616-9276-ee9d3d7842b6"},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1670885918023,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"8448da89-28b4-4457-82fd-2a3bf492ae66","outputId":"8544d765-2f6d-48a4-cbc8-e58347219638"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total lines: 671,370\n"]}],"source":["fin1_n = line_count(f\"{data_dir}/sentences.jpn\")\n","fin2_n = line_count(f\"{data_dir}/cc100.ja.mod1k.txt\")\n","fin_chain_n = fin1_n + fin2_n\n","print(f\"Total lines: {fin_chain_n:,}\")"],"id":"8448da89-28b4-4457-82fd-2a3bf492ae66"},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1670885918024,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"55a64112-c9a3-4b18-8dab-cd9273bc7304","outputId":"094ea4b8-17d6-4745-f673-3bdafa8e505d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating chp05_03/data/raw_text\n"]}],"source":["raw_text = data_dir / \"raw_text\"\n","\n","if not raw_text.is_dir():\n","    print(f\"Creating {raw_text}\")\n","    raw_text.mkdir()\n","else:\n","    print(f\"{raw_text} exists.\")"],"id":"55a64112-c9a3-4b18-8dab-cd9273bc7304"},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222004,"status":"ok","timestamp":1670886140019,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"f550268a-2335-431f-b308-e250fdefdc23","outputId":"dcec2c3f-5248-4b33-f4d0-a8e95187163e"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 671370/671370 [03:42<00:00, 3020.38it/s]\n"]}],"source":["if not (Path(f\"{raw_text}/tatoeba_cc100.kan\").is_file() and Path(f\"{raw_text}/tatoeba_cc100.rom\").is_file()):\n","    \n","    with open(f\"{data_dir}/sentences.jpn\") as fin1, \\\n","        open(f\"{data_dir}/cc100.ja.mod1k.txt\") as fin2, \\\n","        open(f\"{raw_text}/tatoeba_cc100.kan\", mode='w') as f_kan, \\\n","        open(f\"{raw_text}/tatoeba_cc100.rom\", mode='w') as f_rom:\n","\n","        for line in tqdm(chain(fin1, fin2), total=fin_chain_n):\n","            sent_kan = line.strip()\n","            if not sent_kan:\n","                continue\n","            if len(sent_kan) > 256:\n","                # skip long sentences\n","                continue\n","\n","            try:\n","                # Hack to remove odoriji ヾ, otherwise it crashes cutlet.Cutlet().romaji()\n","                # str.replace() should be fast enough here.\n","                sent_kan = sent_kan.replace(\"ヾ\", \"\")             \n","                sent_rom = katsu.romaji(sent_kan)\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","                continue\n","\n","            sent_rom = sent_rom.replace(' ', '') \n","            f_kan.write(sent_kan + '\\n')\n","            f_rom.write(sent_rom + '\\n')\n","            \n","else:\n","    print(f\"{raw_text}/tatoeba_cc100.rom exists.\")\n","    print(f\"{raw_text}/tatoeba_cc100.kan exists.\")                            "],"id":"f550268a-2335-431f-b308-e250fdefdc23"},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1670886140510,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"3e3a4fb8-788a-4fb9-b052-68397895c9d4","outputId":"0d2066e8-957c-44c2-e9c3-616715d6ac07"},"outputs":[{"output_type":"stream","name":"stdout","text":["==> chp05_03/data/raw_text/tatoeba_cc100.kan <==\n","きみにちょっとしたものをもってきたよ。\n","何かしてみましょう。\n","私は眠らなければなりません。\n","何してるの？\n","今日は６月１８日で、ムーリエルの誕生日です！\n","お誕生日おめでとうムーリエル！\n","ムーリエルは２０歳になりました。\n","パスワードは「Muiriel」です。\n","すぐに戻ります。\n","知らない。\n","\n","==> chp05_03/data/raw_text/tatoeba_cc100.rom <==\n","Kiminichottoshitamonowomottekitayo.\n","Nankashitemimashou.\n","Watakushiwanemuranakerebanarimasen.\n","Nanshiteruno?\n","Kyouwa6tsuki18kade,Muurierunotanjouhidesu!\n","OtanjouhiomedetouMuurieru!\n","Muurieruwa20saininarimashita.\n","Pasuwaadowa\"Muiriel\"desu.\n","Sugunimodorimasu.\n","Shiranai.\n"]}],"source":["!head -n 10 {raw_text}/tatoeba_cc100.kan {raw_text}/tatoeba_cc100.rom"],"id":"3e3a4fb8-788a-4fb9-b052-68397895c9d4"},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1670886140511,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"2DhmYKAfClmN","outputId":"d9990926-a63d-4bbe-f77f-544895b49447"},"outputs":[{"output_type":"stream","name":"stdout","text":["ｺﾝﾊﾞﾝﾊｰ(･∀･`o)ﾉ))明細書については、今日中に一通り終わらせないと先行きが不安ですが、普通にムリだろうなと諦めています。 葛西りいちさんの作品をできれば電子書籍で読みたいんです。スキャナで自炊するのは面倒 … [Read more…]\n","Konbanhaa))meisaishonitsuitewa,kyoujuunihitotooriowarasenaitosakiyukigafuandesuga,futsuunimuridarounatoakirameteimasu.KasaiRiichisannosakuhinwodekirebadenshishosekideyomitaindesu.sukyanadejisuisurunowamendou...[Readmore...]\n"]}],"source":["# Check the result of replacing odoriji ヾ. Note that hankaku-katakana still remains.\n","odoriji_check = !grep -n --binary-files=text 明細書については {raw_text}/tatoeba_cc100.kan | cut -d ':' -f1\n","!sed -n '{odoriji_check[0]}p' {raw_text}/tatoeba_cc100.kan\n","!sed -n '{odoriji_check[0]}p' {raw_text}/tatoeba_cc100.rom"],"id":"2DhmYKAfClmN"},{"cell_type":"markdown","metadata":{"id":"de0fb05f-4940-4643-afd8-3b62066f5a64"},"source":["<a name='5.3.3'></a><a id='5.3.3'></a>\n","## 5.3.3 Training and Tokenizing with SentencePiece (subword tokenization)\n","<a href=\"#top\">[back to top]</a>\n","\n","We are using the SentencePiece Python Wrapper.\n","\n","Training is performed by passing parameters of spm_train to SentencePieceTrainer.train() function.\n","\n","Training API (quick example)\n","\n","```\n","% spm_train --input=<input> --model_prefix=<model_name> --vocab_size=8000 --character_coverage=1.0 --model_type=<type>\n","```\n","* `--input`: one-sentence-per-line **raw** corpus file. No need to run\n","  tokenizer, normalizer or preprocessor. By default, SentencePiece normalizes\n","  the input with Unicode NFKC. You can pass a comma-separated list of files.\n","* `--model_prefix`: output model name prefix. `<model_name>.model` and `<model_name>.vocab` are generated.\n","* `--vocab_size`: vocabulary size, e.g., 8000, 16000, or 32000\n","* `--character_coverage`: amount of characters covered by the model, good defaults are: `0.9995` for languages with rich character set like Japanese or Chinese and `1.0` for other languages with small character set.\n","* `--model_type`: model type. Choose from `unigram` (default), `bpe`, `char`, or `word`. The input sentence must be pretokenized when using `word` type.\n","\n","Resources:\n","\n","* https://github.com/google/sentencepiece\n","* https://github.com/google/sentencepiece/blob/master/python/README.md\n","* https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb\n","* https://github.com/google/sentencepiece/blob/master/doc/options.md#training-options"],"id":"de0fb05f-4940-4643-afd8-3b62066f5a64"},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1670886140758,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"tjWj6bew9wXH","outputId":"dd665c0b-ffb4-4c78-d24a-d73a4f2b5356"},"outputs":[{"output_type":"stream","name":"stdout","text":["きみにちょっとしたものをもってきたよ。\n","何かしてみましょう。\n","私は眠らなければなりません。\n","何してるの？\n","今日は６月１８日で、ムーリエルの誕生日です！\n"]}],"source":["!head -n 5 {raw_text}/tatoeba_cc100.kan"],"id":"tjWj6bew9wXH"},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78316,"status":"ok","timestamp":1670886219067,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"d94fab48-2bad-4c4e-b876-c99dcc22aeaf","outputId":"01abb9c8-6704-449c-c369-7592158ca46e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating SentencePiece models in chp05_03/data/sp_tokenizer_models.\n"]}],"source":["sp_tokenizer_models = data_dir / \"sp_tokenizer_models\"\n","\n","if not sp_tokenizer_models.is_dir():\n","    print(f\"Creating SentencePiece models in {sp_tokenizer_models}.\")\n","    sp_tokenizer_models.mkdir()\n","else:\n","    print(f\"{sp_tokenizer_models} exists.\")"],"id":"d94fab48-2bad-4c4e-b876-c99dcc22aeaf"},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1670886219382,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"KXS3EsnaEf0w","outputId":"0e03ecf8-5e9c-4ab6-c280-a26d7871a1b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create SentencePiece tokenizer models for kanji data in chp05_03/data/sp_tokenizer_models.\n","Done.\n"]}],"source":["if not Path(sp_tokenizer_models / \"tatoeba_cc100.kan.spm.model\").is_file():\n","    \n","    print(f\"Create SentencePiece tokenizer models for kanji data in {sp_tokenizer_models}.\")\n","    spm.SentencePieceTrainer.train(\n","        input=f'{raw_text}/tatoeba_cc100.kan',\n","        model_prefix=f'{sp_tokenizer_models}/tatoeba_cc100.kan.spm',\n","        vocab_size=10_000,\n","        input_sentence_size=100_000,\n","        shuffle_input_sentence=True,\n","        minloglevel=1\n","    )\n","    print(\"Done.\")\n","else:\n","    print(f\"File {sp_tokenizer_models}/tatoeba_cc100.kan.spm.model exists.\")"],"id":"KXS3EsnaEf0w"},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294468,"status":"ok","timestamp":1670886513844,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"a8a8d11f-283b-4ecc-98a9-319a01c9fba1","outputId":"abdcaafa-87a9-4620-a751-856f90507621"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create SentencePiece tokenizer models for romaji data in chp05_03/data/sp_tokenizer_models.\n","Done.\n"]}],"source":["if not Path(sp_tokenizer_models / \"tatoeba_cc100.rom.spm.model\").is_file():\n","    \n","    print(f\"Create SentencePiece tokenizer models for romaji data in {sp_tokenizer_models}.\")\n","    spm.SentencePieceTrainer.train(\n","        input=f'{raw_text}/tatoeba_cc100.rom',\n","        model_prefix=f'{sp_tokenizer_models}/tatoeba_cc100.rom.spm',\n","        vocab_size=1_000,\n","        input_sentence_size=100_000,\n","        shuffle_input_sentence=True,\n","        minloglevel=1\n","    )\n","    print(\"Done.\")\n","else:\n","    print(f\"File {sp_tokenizer_models}/tatoeba_cc100.rom.spm.model exists.\")"],"id":"a8a8d11f-283b-4ecc-98a9-319a01c9fba1"},{"cell_type":"markdown","metadata":{"id":"b3cf571f-abeb-4b0b-8105-d36d2a52b914"},"source":["---\n","* Test the trained tokenization models on a few examples."],"id":"b3cf571f-abeb-4b0b-8105-d36d2a52b914"},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1670886513845,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"63493404-540a-4a6b-b409-1956a0ed5812","outputId":"463a456e-afd8-4242-fcd8-68e555c908aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x7f0bd7898ab0> >"]},"metadata":{},"execution_count":22}],"source":["# Makes segmenter instance and loads the model file\n","sp_kan = spm.SentencePieceProcessor(\n","    model_file=f\"{sp_tokenizer_models}/tatoeba_cc100.kan.spm.model\"\n",")\n","sp_kan"],"id":"63493404-540a-4a6b-b409-1956a0ed5812"},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1670886513846,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"ATIwUq4FRh27","outputId":"745cbd14-0de0-4e18-8731-61912de882b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["['▁これは', 'テスト', 'です', '。']\n"]}],"source":["# id <=> piece conversion\n","print(sp_kan.id_to_piece(sp_kan.encode(\"これはテストです。\")))"],"id":"ATIwUq4FRh27"},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1670886513848,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"YTQWs2vD_Ba2","outputId":"7429835c-64a7-4092-ecd5-0b2d588c0c8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["['▁', '<unk>', '魅', '<unk>', 'が', '<unk>', 'する']\n"]}],"source":["# This causes more problems for the tokenizer\n","print(sp_kan.id_to_piece(sp_kan.encode(\"魑魅魍魎が跋扈する\")))"],"id":"YTQWs2vD_Ba2"},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1670886513848,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"bd741c1e-8780-42bf-8275-d654448702b7","outputId":"06ac9a54-c106-478b-efc4-3745a01f1ca4"},"outputs":[{"output_type":"stream","name":"stdout","text":["['▁Kore', 'wa', 'te', 'suto', 'desu', '.']\n"]}],"source":["sp_rom = spm.SentencePieceProcessor(\n","    model_file=f\"{sp_tokenizer_models}/tatoeba_cc100.rom.spm.model\"\n",")\n","\n","print(sp_rom.id_to_piece(sp_rom.encode(\"Korewatesutodesu.\")))"],"id":"bd741c1e-8780-42bf-8275-d654448702b7"},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1670886513849,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"8b3d086f-baa4-482d-9689-bdef810ae2c2","outputId":"9dc196ed-6cb1-4014-a3c5-e1b8ad24cef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenize the entire corpus in chp05_03/data/tokenized_corpus.\n"]}],"source":["tokenized_corpus = data_dir / \"tokenized_corpus\"\n","\n","if not tokenized_corpus.is_dir():\n","    print(f\"Tokenize the entire corpus in {tokenized_corpus}.\")\n","    tokenized_corpus.mkdir()\n","else:\n","    print(f\"{tokenized_corpus} exists.\")"],"id":"8b3d086f-baa4-482d-9689-bdef810ae2c2"},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1670886513850,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"ee2837d1-b8c9-41be-9359-b31415b39733"},"outputs":[],"source":["def tokenize_corpus_fn(spp, file_source, file_target):\n","    fin_n = line_count(file_source)\n","    print(f\"Writing to {file_target}\")\n","\n","    with open(file_source) as fin, open(file_target, mode=\"w\") as fout:\n","        for line in tqdm(fin, total=fin_n):\n","            sent_jpn = line.strip()\n","            tokens = spp.id_to_piece(spp.encode(sent_jpn))\n","            # Join all items into a single string, with space character as separator.\n","            fout.write(\" \".join(tokens) + \"\\n\")"],"id":"ee2837d1-b8c9-41be-9359-b31415b39733"},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26678,"status":"ok","timestamp":1670886540509,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"70c3c836-3c5d-455f-a21e-35146728534d","outputId":"1012541a-7767-405b-8a04-83c7ef685858"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing to chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.kan\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 603144/603144 [00:26<00:00, 22729.74it/s]\n"]}],"source":["# Tokenize the kanji corpus\n","file_source_kan = f\"{raw_text}/tatoeba_cc100.kan\"\n","file_target_kan = f\"{tokenized_corpus}/tatoeba_cc100.tok.kan\"\n","\n","if not Path(f\"{tokenized_corpus}/tatoeba_cc100.tok.kan\").is_file():\n","    tokenize_corpus_fn(sp_kan, file_source_kan, file_target_kan)\n","else:\n","    print(f\"{tokenized_corpus}/tatoeba_cc100.tok.kan exists.\")"],"id":"70c3c836-3c5d-455f-a21e-35146728534d"},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33329,"status":"ok","timestamp":1670886573827,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"a2f2f6b4-79df-4943-ac6c-71754417ef9b","outputId":"53a8ceb3-9389-4da1-b1cd-a66556eda83c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing to chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.rom\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 603144/603144 [00:33<00:00, 18061.74it/s]\n"]}],"source":["# Tokenize the romaji corpus\n","file_source_rom = f\"{raw_text}/tatoeba_cc100.rom\"\n","file_target_rom = f\"{tokenized_corpus}/tatoeba_cc100.tok.rom\"\n","\n","if not Path(f\"{tokenized_corpus}/tatoeba_cc100.tok.rom\").is_file():\n","    tokenize_corpus_fn(sp_rom, file_source_rom, file_target_rom)\n","else:\n","    print(f\"{tokenized_corpus}/tatoeba_cc100.tok.rom exists.\")"],"id":"a2f2f6b4-79df-4943-ac6c-71754417ef9b"},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1670886573827,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"1131ba90-53a0-4770-8599-94db1faeece4","outputId":"f8acb228-b778-4826-ada8-9c63aa129533"},"outputs":[{"output_type":"stream","name":"stdout","text":["==> chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.kan <==\n","▁ き み に ちょっとした ものを も ってきた よ 。\n","▁何か してみましょう 。\n","▁私は 眠 ら なければなりません 。\n","▁何 してる の ?\n","▁今日は 6 月 18 日 で 、 ム ー リ エル の 誕生日 です !\n","▁お 誕生日 お め で と う ム ー リ エル !\n","▁ ム ー リ エル は 20 歳 になりました 。\n","▁ パスワード は 「 M u i ri el 」 です 。\n","▁ すぐに 戻り ます 。\n","▁ 知らない 。\n","\n","==> chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.rom <==\n","▁Kimi ni chotto shita monowo mo ttekita yo .\n","▁Nan ka shite mi mashou .\n","▁Watakushiwa ne mu ra nakereba n arimasen .\n","▁Nan shite runo ?\n","▁Kyou wa 6 tsuki 18 ka de , M u u ri eru no tan jou hi desu !\n","▁O tan jou hi o me de tou M u u ri eru !\n","▁Mu u ri eru wa 20 sai ninarimashita .\n","▁ P a su wa a do wa \" M u i ri e l \" desu .\n","▁Su gu nimo do rimasu .\n","▁Shi ranai .\n"]}],"source":["# Examine the first 10 lines from each file\n","!head -n 10 {tokenized_corpus}/tatoeba_cc100.tok.kan {tokenized_corpus}/tatoeba_cc100.tok.rom"],"id":"1131ba90-53a0-4770-8599-94db1faeece4"},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1670886573827,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"519df78f-a675-42fb-8c8f-5747b2c88266"},"outputs":[],"source":["def create_validation_set(file, target):\n","    if not Path(tokenized_corpus / file).is_file():\n","        print(\"Create validation dataset.\")\n","        # NR stands for Number Record\n","        # Get only every 100th line\n","        !awk 'NR%100==0' {target} > {tokenized_corpus}/{file}\n","    else:\n","        print(f\"{tokenized_corpus}/{file} exists.\")\n","\n","    print(f\"line count: {line_count(f'{tokenized_corpus}/{file}'):,}\")"],"id":"519df78f-a675-42fb-8c8f-5747b2c88266"},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1670886574233,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"820b152f-f256-4bbb-8c63-0b342efce34b","outputId":"fc72ff41-438c-47b5-9788-492cafdddeee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create validation dataset.\n","line count: 6,031\n"]}],"source":["# Create Kanji validation set\n","create_validation_set(\"tatoeba_cc100.tok.valid.kan\", file_target_kan)"],"id":"820b152f-f256-4bbb-8c63-0b342efce34b"},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1670886574234,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"5d7b0d2d-ec69-40ee-9e9a-06c967a79b40","outputId":"4347d62e-b52d-4894-8dcc-c445cf23c005"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create validation dataset.\n","line count: 6,031\n"]}],"source":["# Create Romaji validation set\n","create_validation_set(\"tatoeba_cc100.tok.valid.rom\", file_target_rom)"],"id":"5d7b0d2d-ec69-40ee-9e9a-06c967a79b40"},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1670886574235,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"553eee7a-7ba0-437c-8735-30216a76c673"},"outputs":[],"source":["def create_training_set(file, target):\n","    if not Path(tokenized_corpus / file).is_file():\n","        print(\"Create training dataset.\")\n","        # NR stands for Number Record\n","        # Get every line except every 100th\n","        !awk 'NR%100!=0' {target} > {tokenized_corpus}/{file}\n","    else:\n","        print(f\"{tokenized_corpus}/{file} exists.\")\n","\n","    print(f\"line count: {line_count(f'{tokenized_corpus}/{file}'):,}\")"],"id":"553eee7a-7ba0-437c-8735-30216a76c673"},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":679,"status":"ok","timestamp":1670886574906,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"63838766-56b7-4a6b-a62a-11b564f38555","outputId":"5226de84-8ccc-4ac5-df2b-4621043781c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create training dataset.\n","line count: 597,113\n"]}],"source":["# Create Kanji training set\n","create_training_set(\"tatoeba_cc100.tok.train.kan\", file_target_kan)"],"id":"63838766-56b7-4a6b-a62a-11b564f38555"},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1670886575159,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"9c899b38-0a29-4332-a51e-94927e95ac2a","outputId":"462f4135-77fc-4842-b7ee-d8a37a834291"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create training dataset.\n","line count: 597,113\n"]}],"source":["# Create Romaji training set\n","create_training_set(\"tatoeba_cc100.tok.train.rom\", file_target_rom)"],"id":"9c899b38-0a29-4332-a51e-94927e95ac2a"},{"cell_type":"markdown","metadata":{"id":"d3e52e2a-5a4c-42b3-9b1d-fdbf361384d9"},"source":["<a name='5.3.4'></a><a id='5.3.4'></a>\n","## 5.3.4 Training a Conversion Model with Fairseq\n","<a href=\"#top\">[back to top]</a>\n","\n","* Fairseq is a sequence modeling toolkit by Meta AI\n","* It implements major sequence models such as the Transformer-based seq2seq model.\n","* We need to first convert the raw text corpus into a binary format.\n","* This creates binary files for each language and data split.\n","\n","Fairseq(-py) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks.\n","\n","fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs\n","\n","Reference:\n","\n","* https://github.com/facebookresearch/fairseq\n","* https://aclanthology.org/N19-4009.pdf\n","* https://www.youtube.com/watch?v=OtgDdWtHvto"],"id":"d3e52e2a-5a4c-42b3-9b1d-fdbf361384d9"},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1670886575159,"user":{"displayName":"George Baptista","userId":"16776465488006883803"},"user_tz":-540},"id":"157aac0c-a8d4-4ec9-af10-484ab02dba1f","outputId":"56d6a1d4-a4a1-46f8-d0b0-d4e1dfe3a806"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('chp05_03/data/bin')"]},"metadata":{},"execution_count":37}],"source":["bin = data_dir / \"bin\"\n","bin"],"id":"157aac0c-a8d4-4ec9-af10-484ab02dba1f"},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bf886bf-a517-4f0b-89f0-67072411a941","executionInfo":{"status":"ok","timestamp":1670886862148,"user_tz":-540,"elapsed":286996,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"8f464169-45ee-4f36-ab8a-5abc529e314a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converting raw text corpus to a binary format.\n","--------------------------------------------------\n","2022-12-12 23:09:36 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='chp05_03/data/bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='rom', srcdict=None, suppress_crashes=False, target_lang='kan', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.train', use_plasma_view=False, user_dir=None, validpref='chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.valid', wandb_project=None, workers=4)\n","2022-12-12 23:10:47 | INFO | fairseq_cli.preprocess | [rom] Dictionary: 1008 types\n","2022-12-12 23:12:31 | INFO | fairseq_cli.preprocess | [rom] chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.train.rom: 597113 sents, 21224028 tokens, 0.0% replaced (by <unk>)\n","2022-12-12 23:12:31 | INFO | fairseq_cli.preprocess | [rom] Dictionary: 1008 types\n","2022-12-12 23:12:32 | INFO | fairseq_cli.preprocess | [rom] chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.valid.rom: 6031 sents, 214974 tokens, 0.0% replaced (by <unk>)\n","2022-12-12 23:12:32 | INFO | fairseq_cli.preprocess | [kan] Dictionary: 10000 types\n","2022-12-12 23:14:19 | INFO | fairseq_cli.preprocess | [kan] chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.train.kan: 597113 sents, 15558841 tokens, 0.0% replaced (by <unk>)\n","2022-12-12 23:14:19 | INFO | fairseq_cli.preprocess | [kan] Dictionary: 10000 types\n","2022-12-12 23:14:20 | INFO | fairseq_cli.preprocess | [kan] chp05_03/data/tokenized_corpus/tatoeba_cc100.tok.valid.kan: 6031 sents, 157550 tokens, 0.0% replaced (by <unk>)\n","2022-12-12 23:14:20 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to chp05_03/data/bin\n","--------------------------------------------------\n","Done\n"]}],"source":["# rom: Romaji\n","# kan: Kanji\n","if not bin.is_dir():\n","    print(\"Converting raw text corpus to a binary format.\")\n","    HR() \n","    !fairseq-preprocess --source-lang rom --target-lang kan \\\n","        --trainpref {tokenized_corpus}/tatoeba_cc100.tok.train \\\n","        --validpref {tokenized_corpus}/tatoeba_cc100.tok.valid \\\n","        --destdir {bin} \\\n","        --workers 4\n","    HR()\n","    print(\"Done\")\n","else:\n","    print(f\"{bin} exists\")"],"id":"1bf886bf-a517-4f0b-89f0-67072411a941"},{"cell_type":"markdown","metadata":{"id":"485c82f7-ad44-452e-9fa5-9cb05cbd5126"},"source":["* Run fairseq-train to start the training process."],"id":"485c82f7-ad44-452e-9fa5-9cb05cbd5126"},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c5204d9-4b92-4cbe-8d8b-8be58ff993db","executionInfo":{"status":"ok","timestamp":1670886862149,"user_tz":-540,"elapsed":25,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"edc85593-66c0-4c65-e07d-f67c398cea5e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":39}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"id":"3c5204d9-4b92-4cbe-8d8b-8be58ff993db"},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cc3b1a0a-d8e4-4c7d-a7ac-552a142d3dbd","executionInfo":{"status":"ok","timestamp":1670886862151,"user_tz":-540,"elapsed":18,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"c438388b-d082-4219-df65-28bce40941ca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('chp05_03/data/models')"]},"metadata":{},"execution_count":40}],"source":["models = data_dir / \"models\"\n","models"],"id":"cc3b1a0a-d8e4-4c7d-a7ac-552a142d3dbd"},{"cell_type":"code","execution_count":41,"metadata":{"id":"39d5094c-9d7f-49ca-8ad4-d7d53c32eca6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670887728474,"user_tz":-540,"elapsed":866337,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"935ee7b2-c741-4b7a-f3d8-905bcaa2f120"},"outputs":[{"output_type":"stream","name":"stdout","text":["Start training with fairseq-train on COLAB\n","--------------------------------------------------\n","2022-12-12 23:14:25 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 16384, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 16384, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'chp05_03/data/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer', activation_dropout=0.0, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', cross_self_attention=False, curriculum=0, data='chp05_03/data/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0002], lr_scheduler='inverse_sqrt', max_epoch=2, max_tokens=16384, max_tokens_valid=16384, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='checkpoint_last.pt', save_dir='chp05_03/data/models', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'chp05_03/data/bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2022-12-12 23:14:25 | INFO | fairseq.tasks.translation | [rom] dictionary: 1008 types\n","2022-12-12 23:14:25 | INFO | fairseq.tasks.translation | [kan] dictionary: 10000 types\n","2022-12-12 23:14:25 | INFO | fairseq_cli.train | TransformerModel(\n","  (encoder): TransformerEncoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(1008, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(10000, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (output_projection): Linear(in_features=512, out_features=10000, bias=False)\n","  )\n",")\n","2022-12-12 23:14:25 | INFO | fairseq_cli.train | task: TranslationTask\n","2022-12-12 23:14:25 | INFO | fairseq_cli.train | model: TransformerModel\n","2022-12-12 23:14:25 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion\n","2022-12-12 23:14:25 | INFO | fairseq_cli.train | num. shared model params: 52,783,104 (num. trained: 52,783,104)\n","2022-12-12 23:14:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n","2022-12-12 23:14:25 | INFO | fairseq.data.data_utils | loaded 6,031 examples from: chp05_03/data/bin/valid.rom-kan.rom\n","2022-12-12 23:14:25 | INFO | fairseq.data.data_utils | loaded 6,031 examples from: chp05_03/data/bin/valid.rom-kan.kan\n","2022-12-12 23:14:25 | INFO | fairseq.tasks.translation | chp05_03/data/bin valid rom-kan 6031 examples\n","2022-12-12 23:14:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2022-12-12 23:14:29 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n","2022-12-12 23:14:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2022-12-12 23:14:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n","2022-12-12 23:14:29 | INFO | fairseq_cli.train | max tokens per device = 16384 and max sentences per device = None\n","2022-12-12 23:14:29 | INFO | fairseq.trainer | Preparing to load checkpoint chp05_03/data/models/checkpoint_last.pt\n","2022-12-12 23:14:29 | INFO | fairseq.trainer | No existing checkpoint found chp05_03/data/models/checkpoint_last.pt\n","2022-12-12 23:14:29 | INFO | fairseq.trainer | loading train data for epoch 1\n","2022-12-12 23:14:29 | INFO | fairseq.data.data_utils | loaded 597,113 examples from: chp05_03/data/bin/train.rom-kan.rom\n","2022-12-12 23:14:29 | INFO | fairseq.data.data_utils | loaded 597,113 examples from: chp05_03/data/bin/train.rom-kan.kan\n","2022-12-12 23:14:29 | INFO | fairseq.tasks.translation | chp05_03/data/bin train rom-kan 597113 examples\n","2022-12-12 23:14:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1342\n","epoch 001:   0% 0/1342 [00:00<?, ?it/s]2022-12-12 23:14:30 | INFO | fairseq.trainer | begin training epoch 1\n","2022-12-12 23:14:30 | INFO | fairseq_cli.train | Start iterating over samples\n","2022-12-12 23:14:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n","epoch 001:   0% 1/1342 [00:03<1:15:33,  3.38s/it]2022-12-12 23:14:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n","epoch 001:   1% 7/1342 [00:05<09:00,  2.47it/s]2022-12-12 23:14:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n","epoch 001:   4% 55/1342 [00:18<05:28,  3.91it/s]2022-12-12 23:14:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n","epoch 001: 100% 1341/1342 [06:47<00:00,  3.21it/s, loss=8.709, ppl=418.57, wps=36600.9, ups=3.16, wpb=11582.1, bsz=388, num_updates=1300, lr=6.5e-05, gnorm=2.369, loss_scale=8, train_wall=31, gb_free=10.4, wall=396]2022-12-12 23:21:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 001 | valid on 'valid' subset:   0% 0/17 [00:00<?, ?it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:   6% 1/17 [00:00<00:03,  5.16it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  18% 3/17 [00:00<00:01,  8.17it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  24% 4/17 [00:00<00:01,  8.71it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  29% 5/17 [00:00<00:01,  8.87it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  41% 7/17 [00:00<00:01,  9.77it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  53% 9/17 [00:00<00:00,  9.77it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  59% 10/17 [00:01<00:00,  9.30it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  71% 12/17 [00:01<00:00,  9.37it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  76% 13/17 [00:01<00:00,  9.49it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  82% 14/17 [00:01<00:00,  9.18it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  88% 15/17 [00:01<00:00,  9.12it/s]\u001b[A\n","                                                                        \u001b[A2022-12-12 23:21:19 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.056 | ppl 266.2 | wps 96609.4 | wpb 9267.6 | bsz 354.8 | num_updates 1338\n","2022-12-12 23:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1338 updates\n","2022-12-12 23:21:19 | INFO | fairseq.trainer | Saving checkpoint to /content/chp05_03/data/models/checkpoint_best.pt\n","2022-12-12 23:21:22 | INFO | fairseq.trainer | Finished saving checkpoint to /content/chp05_03/data/models/checkpoint_best.pt\n","2022-12-12 23:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint chp05_03/data/models/checkpoint_best.pt (epoch 1 @ 1338 updates, score 8.056) (writing took 5.006077300000015 seconds)\n","2022-12-12 23:21:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n","2022-12-12 23:21:24 | INFO | train | epoch 001 | loss 10.101 | ppl 1098.58 | wps 37766.1 | ups 3.26 | wpb 11593 | bsz 443.7 | num_updates 1338 | lr 6.69e-05 | gnorm 2.243 | loss_scale 8 | train_wall 404 | gb_free 10.5 | wall 415\n","2022-12-12 23:21:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1342\n","epoch 002:   0% 0/1342 [00:00<?, ?it/s]2022-12-12 23:21:24 | INFO | fairseq.trainer | begin training epoch 2\n","2022-12-12 23:21:24 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 002: 100% 1341/1342 [07:05<00:00,  3.24it/s, loss=3.979, ppl=15.77, wps=35916.5, ups=3.14, wpb=11431.4, bsz=474.2, num_updates=2600, lr=0.00013, gnorm=4.096, loss_scale=8, train_wall=32, gb_free=10.8, wall=816]2022-12-12 23:28:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 002 | valid on 'valid' subset:   0% 0/17 [00:00<?, ?it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:   6% 1/17 [00:00<00:02,  5.85it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  18% 3/17 [00:00<00:01,  8.67it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  24% 4/17 [00:00<00:01,  9.06it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  29% 5/17 [00:00<00:01,  9.16it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  41% 7/17 [00:00<00:01, 10.00it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  53% 9/17 [00:00<00:00,  9.73it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  59% 10/17 [00:01<00:00,  9.16it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  65% 11/17 [00:01<00:00,  9.34it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  71% 12/17 [00:01<00:00,  9.23it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  82% 14/17 [00:01<00:00,  9.29it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  88% 15/17 [00:01<00:00,  9.19it/s]\u001b[A\n","                                                                        \u001b[A2022-12-12 23:28:32 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 3.072 | ppl 8.41 | wps 96171.8 | wpb 9267.6 | bsz 354.8 | num_updates 2680 | best_loss 3.072\n","2022-12-12 23:28:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2680 updates\n","2022-12-12 23:28:32 | INFO | fairseq.trainer | Saving checkpoint to /content/chp05_03/data/models/checkpoint_best.pt\n","2022-12-12 23:28:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/chp05_03/data/models/checkpoint_best.pt\n","2022-12-12 23:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint chp05_03/data/models/checkpoint_best.pt (epoch 2 @ 2680 updates, score 3.072) (writing took 4.688794220000091 seconds)\n","2022-12-12 23:28:37 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n","2022-12-12 23:28:37 | INFO | train | epoch 002 | loss 5.88 | ppl 58.88 | wps 35964.5 | ups 3.1 | wpb 11593.8 | bsz 444.9 | num_updates 2680 | lr 0.000134 | gnorm 3.481 | loss_scale 8 | train_wall 422 | gb_free 10.1 | wall 847\n","2022-12-12 23:28:37 | INFO | fairseq_cli.train | done training in 847.2 seconds\n","--------------------------------------------------\n","Done.\n"]}],"source":["if models.is_dir():\n","    print(f\"fairseq-train model exists at {models}\")\n","\n","else:\n","\n","    if IS_COLAB:\n","        print(\"Start training with fairseq-train on COLAB\")\n","        HR()\n","        !fairseq-train \\\n","            {bin} \\\n","            --max-tokens 16384 \\\n","            --arch transformer \\\n","            --encoder-layers 4 \\\n","            --decoder-layers 4 \\\n","            --encoder-embed-dim 512 \\\n","            --decoder-embed-dim 512 \\\n","            --encoder-ffn-embed-dim 2048 \\\n","            --decoder-ffn-embed-dim 2048 \\\n","            --encoder-attention-heads 8 \\\n","            --decoder-attention-heads 8 \\\n","            --optimizer adam --lr 2e-4 \\\n","            --lr-scheduler inverse_sqrt \\\n","            --warmup-updates 4000 \\\n","            --save-dir {models} \\\n","            --max-epoch 2 \\\n","            --reset-optimizer \\\n","            --no-epoch-checkpoints \\\n","            --fp16\n","\n","            # --max-epoch 10 \\\n","            \n","    else:\n","\n","        print(\"Start training with fairseq-train locally (non-GPU)\")\n","        HR()\n","        !fairseq-train \\\n","            {bin} \\\n","            --max-tokens 16384 \\\n","            --arch transformer \\\n","            --encoder-layers 4 \\\n","            --decoder-layers 4 \\\n","            --encoder-embed-dim 512 \\\n","            --decoder-embed-dim 512 \\\n","            --encoder-ffn-embed-dim 2048 \\\n","            --decoder-ffn-embed-dim 2048 \\\n","            --encoder-attention-heads 8 \\\n","            --decoder-attention-heads 8 \\\n","            --optimizer adam --lr 2e-4 \\\n","            --lr-scheduler inverse_sqrt \\\n","            --warmup-updates 4000 \\\n","            --save-dir {models} \\\n","            --max-epoch 1 \\\n","            --no-epoch-checkpoints \\\n","            --cpu\n","\n","    HR()\n","    print(\"Done.\")"],"id":"39d5094c-9d7f-49ca-8ad4-d7d53c32eca6"},{"cell_type":"code","execution_count":42,"metadata":{"id":"1a7799dc-e7ab-4277-9a1e-5d5081cd03d5","executionInfo":{"status":"ok","timestamp":1670887728475,"user_tz":-540,"elapsed":22,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}}},"outputs":[],"source":["sp_tatoeba = spm.SentencePieceProcessor(model_file=f\"{sp_tokenizer_models}/tatoeba_cc100.rom.spm.model\")\n","\n","test_sentences = [\n","    'Kishaninoru.',\n","    'Shinbunkisha.',\n","    'Nunodefuku.',\n","    'Furuutowofuku.',\n","    'Nunodefuruutowofuku.',\n","    'Kikaigakushuuwobenkyousurumatatonaikikai.',\n","    'Jinkouchinounikyouminoarujinkougafueteiru.',\n","    'Kougakubunogakuhiwahijounikougakuninatta.',\n","    'Reizoukonishougaganainarashouganai.',\n","    'Chikatetsunarimasueki.',\n","    'Karumenmenyoripaeriasuki.'\n","]\n","\n","rom_tokenized = [' '.join(sp_tatoeba.id_to_piece(sp_tatoeba.encode(rom))) for rom in test_sentences]"],"id":"1a7799dc-e7ab-4277-9a1e-5d5081cd03d5"},{"cell_type":"code","execution_count":43,"metadata":{"id":"r1voRszPKxsU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670887728476,"user_tz":-540,"elapsed":20,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"95e3a394-d92a-4583-8e08-5b62a6ed299d"},"outputs":[{"output_type":"stream","name":"stdout","text":["▁Ki sha ni no ru .\n","▁Shi n bun ki sha .\n","▁ N u node fuku .\n","▁Fu ru u to wo fuku .\n","▁ N u node fu ru u to wo fuku .\n","▁Ki kai gaku shuu wo benkyou suru mata to nai ki kai .\n","▁Ji n kou chi nou ni kyou mi no aru jin kou ga fu e teiru .\n","▁Kou gaku bu no gaku hi wa hijouni kou gaku ninatta .\n","▁ R ei zou ko ni shou ga ganai nara shou ganai .\n","▁Chi ka te tsu n arimasu eki .\n","▁Ka ru men men yori pa e ri a suki .\n"]}],"source":["!echo \"{'\\n'.join(rom_tokenized)}\""],"id":"r1voRszPKxsU"},{"cell_type":"code","execution_count":44,"metadata":{"id":"xzbJNvo2J9gO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670887738595,"user_tz":-540,"elapsed":10128,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"02cb9e7d-e6e8-40f7-9573-9fe27f1a8dcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-12 23:28:53 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'chp05_03/data/models/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1, 'input': '-'}, 'model': None, 'task': {'_name': 'translation', 'data': 'chp05_03/data/bin', 'source_lang': 'rom', 'target_lang': 'kan', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2022-12-12 23:28:53 | INFO | fairseq.tasks.translation | [rom] dictionary: 1008 types\n","2022-12-12 23:28:53 | INFO | fairseq.tasks.translation | [kan] dictionary: 10000 types\n","2022-12-12 23:28:53 | INFO | fairseq_cli.interactive | loading model(s) from chp05_03/data/models/checkpoint_best.pt\n","2022-12-12 23:28:56 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2022-12-12 23:28:56 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","S-0\t▁Ki sha ni no ru .\n","W-0\t0.692\tseconds\n","H-0\t-0.6273123621940613\t▁ 医者 に の る 。\n","D-0\t-0.6273123621940613\t▁ 医者 に の る 。\n","P-0\t-0.0154 -2.3359 -0.2164 -1.1737 -0.6045 -0.0424 -0.0029\n","S-1\t▁Shi n bun ki sha .\n","W-1\t0.036\tseconds\n","H-1\t-0.821837842464447\t▁ 新聞 者 。\n","D-1\t-0.821837842464447\t▁ 新聞 者 。\n","P-1\t-0.1746 -0.2619 -2.4920 -1.1774 -0.0033\n","S-2\t▁ N u node fuku .\n","W-2\t0.037\tseconds\n","H-2\t-0.7585415244102478\t▁ の ので 服 。\n","D-2\t-0.7585415244102478\t▁ の ので 服 。\n","P-2\t-0.0264 -2.1197 -1.7412 -0.5804 -0.0787 -0.0049\n","S-3\t▁Fu ru u to wo fuku .\n","W-3\t0.058\tseconds\n","H-3\t-0.6697763800621033\t▁ 古い と 服 を 服 。\n","D-3\t-0.6697763800621033\t▁ 古い と 服 を 服 。\n","P-3\t-0.0093 -1.9503 -1.1952 -0.7882 -0.5955 -0.7105 -0.1079 -0.0014\n","S-4\t▁ N u node fu ru u to wo fuku .\n","W-4\t0.065\tseconds\n","H-4\t-1.1769416332244873\t▁ の フル ー フル と 服 を 服 。\n","D-4\t-1.1769416332244873\t▁ の フル ー フル と 服 を 服 。\n","P-4\t-0.0238 -2.3602 -3.5413 -1.1745 -2.7764 -0.9182 -0.3011 -0.5152 -1.2414 -0.0915 -0.0027\n","S-5\t▁Ki kai gaku shuu wo benkyou suru mata to nai ki kai .\n","W-5\t0.070\tseconds\n","H-5\t-0.6817967295646667\t▁ 機械 学習 を 勉強 する また 取れ ない 機会 。\n","D-5\t-0.6817967295646667\t▁ 機械 学習 を 勉強 する また 取れ ない 機会 。\n","P-5\t-0.0586 -0.9664 -0.8617 -0.2093 -0.1642 -0.3077 -0.3425 -3.9669 -0.0693 -1.1354 -0.0954 -0.0041\n","S-6\t▁Ji n kou chi nou ni kyou mi no aru jin kou ga fu e teiru .\n","W-6\t0.086\tseconds\n","H-6\t-0.9085425138473511\t▁ 工事 地 の 脳 に 興味 のある 人口 が 増えている 。\n","D-6\t-0.9085425138473511\t▁ 工事 地 の 脳 に 興味 のある 人口 が 増えている 。\n","P-6\t-0.0121 -3.4005 -1.0667 -3.0282 -1.8959 -0.4309 -0.1151 -0.0546 -0.6772 -0.1663 -0.9588 -0.0027 -0.0018\n","S-7\t▁Kou gaku bu no gaku hi wa hijouni kou gaku ninatta .\n","W-7\t0.065\tseconds\n","H-7\t-0.8470039963722229\t▁ 高額 の 学 費 は非常に 高額 になった 。\n","D-7\t-0.8470039963722229\t▁ 高額 の 学 費 は非常に 高額 になった 。\n","P-7\t-0.0232 -2.9300 -0.0844 -1.5692 -1.6068 -0.3654 -1.8374 -0.0422 -0.0086 -0.0029\n","S-8\t▁ R ei zou ko ni shou ga ganai nara shou ganai .\n","W-8\t0.059\tseconds\n","H-8\t-1.043053150177002\t▁ 冷蔵庫 に 招待 がない なら 賞 がない 。\n","D-8\t-1.043053150177002\t▁ 冷蔵庫 に 招待 がない なら 賞 がない 。\n","P-8\t-0.0390 -0.6181 -0.1349 -3.9525 -1.1391 -0.4918 -3.9211 -0.1250 -0.0069 -0.0022\n","S-9\t▁Chi ka te tsu n arimasu eki .\n","W-9\t0.045\tseconds\n","H-9\t-0.5027774572372437\t▁ 地下鉄 あります 。\n","D-9\t-0.5027774572372437\t▁ 地下鉄 あります 。\n","P-9\t-0.0460 -0.5351 -1.2716 -0.6240 -0.0372\n","S-10\t▁Ka ru men men yori pa e ri a suki .\n","W-10\t0.069\tseconds\n","H-10\t-0.8535967469215393\t▁ カル 面 面 より パパ 好き 。\n","D-10\t-0.8535967469215393\t▁ カル 面 面 より パパ 好き 。\n","P-10\t-0.0134 -2.5899 -0.6052 -0.3659 -0.0173 -2.5605 -0.8309 -0.6961 -0.0031\n","2022-12-12 23:28:57 | INFO | fairseq_cli.interactive | Total time: 3.908 seconds; translation time: 1.281\n"]}],"source":["!echo \"{'\\n'.join(rom_tokenized)}\" | fairseq-interactive \\\n","{bin} \\\n","--path {models}/checkpoint_best.pt \\\n","--source-lang rom \\\n","--target-lang kan"],"id":"xzbJNvo2J9gO"},{"cell_type":"code","execution_count":45,"metadata":{"id":"zOd5g0zpoFDx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670887746600,"user_tz":-540,"elapsed":8012,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"fc90a6e0-66f0-4433-e18b-ee056a9882c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["▁ 医者 に の る 。\n","▁ 新聞 者 。\n","▁ の ので 服 。\n","▁ 古い と 服 を 服 。\n","▁ の フル ー フル と 服 を 服 。\n","▁ 機械 学習 を 勉強 する また 取れ ない 機会 。\n","▁ 銀行 の 脳 に 興味 のある 人口 が 増えている 。\n","▁ 高額 の 学 費 は非常に 高額 になった 。\n","▁ 冷蔵庫 に 招待 がない なら 賞 がない 。\n","▁ 地下鉄 あります 。\n","▁ カル 面 面 より パパ 好き 。\n"]}],"source":["!echo \"{'\\n'.join(rom_tokenized)}\" | fairseq-interactive \\\n","{bin} \\\n","--path {models}/checkpoint_best.pt \\\n","--source-lang rom \\\n","--target-lang kan \\\n","--beam 10 2> /dev/null | grep 'H-' | cut -f3"],"id":"zOd5g0zpoFDx"},{"cell_type":"markdown","metadata":{"id":"wAzUAg28zH4L"},"source":["<a name='5.3.4'></a><a id='5.3.4'></a>\n","## 5.3.4 Checking created artifacts\n","<a href=\"#top\">[back to top]</a>"],"id":"wAzUAg28zH4L"},{"cell_type":"code","execution_count":46,"metadata":{"id":"KZQEbwMHzDEc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670887746602,"user_tz":-540,"elapsed":25,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"80b99f57-06ce-464a-d83c-4892477ccfc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["chp05_03\n","├── data\n","│   ├── bin\n","│   │   ├── dict.kan.txt\n","│   │   ├── dict.rom.txt\n","│   │   ├── preprocess.log\n","│   │   ├── train.rom-kan.kan.bin\n","│   │   ├── train.rom-kan.kan.idx\n","│   │   ├── train.rom-kan.rom.bin\n","│   │   ├── train.rom-kan.rom.idx\n","│   │   ├── valid.rom-kan.kan.bin\n","│   │   ├── valid.rom-kan.kan.idx\n","│   │   ├── valid.rom-kan.rom.bin\n","│   │   └── valid.rom-kan.rom.idx\n","│   ├── cc100.ja.mod1k.txt\n","│   ├── models\n","│   │   ├── checkpoint_best.pt\n","│   │   └── checkpoint_last.pt\n","│   ├── raw_text\n","│   │   ├── tatoeba_cc100.kan\n","│   │   └── tatoeba_cc100.rom\n","│   ├── sentences20210924.tar.bz2\n","│   ├── sentences.csv\n","│   ├── sentences.jpn\n","│   ├── sp_tokenizer_models\n","│   │   ├── tatoeba_cc100.kan.spm.model\n","│   │   ├── tatoeba_cc100.kan.spm.vocab\n","│   │   ├── tatoeba_cc100.rom.spm.model\n","│   │   └── tatoeba_cc100.rom.spm.vocab\n","│   └── tokenized_corpus\n","│       ├── tatoeba_cc100.tok.kan\n","│       ├── tatoeba_cc100.tok.rom\n","│       ├── tatoeba_cc100.tok.train.kan\n","│       ├── tatoeba_cc100.tok.train.rom\n","│       ├── tatoeba_cc100.tok.valid.kan\n","│       └── tatoeba_cc100.tok.valid.rom\n","└── requirements_5_5_3.txt\n","\n","6 directories, 30 files\n"]}],"source":["!tree chp05_03"],"id":"KZQEbwMHzDEc"},{"cell_type":"markdown","metadata":{"id":"k7D9iQpanACR"},"source":["<a name='5.3.5'></a><a id='5.3.5'></a>\n","## 5.3.5 Saving artifacts to Google Drive\n","<a href=\"#top\">[back to top]</a>\n","\n","https://drive.google.com/drive/my-drive"],"id":"k7D9iQpanACR"},{"cell_type":"code","execution_count":47,"metadata":{"id":"qF8yJN89TRa7","executionInfo":{"status":"ok","timestamp":1670887746604,"user_tz":-540,"elapsed":14,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}}},"outputs":[],"source":["# If need to start with a clean directory on Google Drive\n","# !rm -fr /content/drive/MyDrive/chp05_03"],"id":"qF8yJN89TRa7"},{"cell_type":"code","execution_count":48,"metadata":{"id":"iYJDu-xyRXBp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670887809773,"user_tz":-540,"elapsed":63182,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"616ecd81-04ae-4e52-a163-9aa27cc733e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","--------------------------------------------------\n","Overwriting /content/drive/MyDrive/chp05_03\n","--------------------------------------------------\n","605M\t/content/drive/MyDrive/chp05_03/data/models/checkpoint_best.pt\n","605M\t/content/drive/MyDrive/chp05_03/data/models\n","--------------------------------------------------\n","Check contents of chp05_03:\n","512\t/content/drive/MyDrive/chp05_03/requirements_5_5_3.txt\n","830K\t/content/drive/MyDrive/chp05_03/data/sp_tokenizer_models\n","12M\t/content/drive/MyDrive/chp05_03/data/sentences.jpn\n","72M\t/content/drive/MyDrive/chp05_03/data/cc100.ja.mod1k.txt\n","85M\t/content/drive/MyDrive/chp05_03/data/bin\n","139M\t/content/drive/MyDrive/chp05_03/data/raw_text\n","147M\t/content/drive/MyDrive/chp05_03/data/sentences20210924.tar.bz2\n","349M\t/content/drive/MyDrive/chp05_03/data/tokenized_corpus\n","515M\t/content/drive/MyDrive/chp05_03/data/sentences.csv\n","605M\t/content/drive/MyDrive/chp05_03/data/models\n","1.9G\t/content/drive/MyDrive/chp05_03\n","1.9G\t/content/drive/MyDrive/chp05_03/data\n"]}],"source":["# Set PUSH_TO_GD to True if you want to push chp05_03 to Google Drive \n","PUSH_TO_GD = True\n","if IS_COLAB and PUSH_TO_GD:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    HR()\n","\n","    print(\"Overwriting /content/drive/MyDrive/chp05_03\")\n","    !cp -R /content/chp05_03  /content/drive/MyDrive\n","    HR()\n","\n","    # Only keep the checkpoint_best.pt model\n","    !rm -fr /content/drive/MyDrive/chp05_03/data/models/checkpoint_last.pt\n","    !du -ha /content/drive/MyDrive/chp05_03/data/models\n","    HR() \n","\n","    print(\"Check contents of chp05_03:\")\n","    !du -ah /content/drive/MyDrive/chp05_03 --max-depth=2 | sort -h"],"id":"iYJDu-xyRXBp"},{"cell_type":"code","execution_count":49,"metadata":{"id":"vR2cn15aDrbI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670887819298,"user_tz":-540,"elapsed":9531,"user":{"displayName":"George Baptista","userId":"16776465488006883803"}},"outputId":"a396eaaa-3dd6-4d6c-bb87-a7b885c0bbdd"},"outputs":[{"output_type":"stream","name":"stdout","text":["▁ 医者 に の る 。\n","▁ 新聞 者 。\n","▁ の ので 服 。\n","▁ 古い と 服 を 服 。\n","▁ の フル ー フル と 服 を 服 。\n","▁ 機械 学習 を 勉強 する また 取れ ない 機会 。\n","▁ 銀行 の 脳 に 興味 のある 人口 が 増えている 。\n","▁ 高額 の 学 費 は非常に 高額 になった 。\n","▁ 冷蔵庫 に 招待 がない なら 賞 がない 。\n","▁ 地下鉄 あります 。\n","▁ カル 面 面 より パパ 好き 。\n"]}],"source":["if PUSH_TO_GD:\n","    # Test that we can do inference on stored on Google Drive\n","    !echo \"{'\\n'.join(rom_tokenized)}\" | fairseq-interactive \\\n","    /content/drive/MyDrive/chp05_03/data/bin \\\n","    --path /content/drive/MyDrive/chp05_03/data/models/checkpoint_best.pt \\\n","    --source-lang rom \\\n","    --target-lang kan \\\n","    --beam 10 2> /dev/null | grep 'H-' | cut -f3"],"id":"vR2cn15aDrbI"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}